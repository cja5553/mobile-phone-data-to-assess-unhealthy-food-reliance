{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9d8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4208960dff8243e3bdfaf07e3c2cd0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4934286c26fa476a96b27d4a9f6a4405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2092038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4a08900375447595e271877de958c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2092038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0f8dcbd98642b09a2218bd1ad24ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2092038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifying wrongly classified grocery stores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352b2d28d96a485583c41777fbca69f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bcc642a401484fa5d923c2dca9fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662b518cb402494a82ddc820e900002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09fa73c2a0d4f7db5ca98a0ecf15b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of list of incorrectly mislabelled grocery stores is:  5879\n",
      "Removing incorrectly classified grocery stores...\n",
      "The total number of convenient store chain names selected is: 24989\n",
      "The number of convenient store locations selected is: 58121\n",
      "Scaling up visitations from census-tract level to county-level\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d05507257447248ff238a62ad5d9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1920776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284b5d9788ab4417a2cde3c179650165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1920776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5401c4a13f41e8a9f0aa23090f4d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15751976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating data...\n",
      "Data Aggregated, saving file...\n",
      "File Saved!\n"
     ]
    }
   ],
   "source": [
    "# loading packages\n",
    "print(\"Reading Files...\")\n",
    "import glob\n",
    "import gzip\n",
    "import tqdm.notebook as tq\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# reading and combining all of the files \n",
    "## (note: safegraph provided the dataset in multiple .gz and .csv folders)\n",
    "ZIPFILES='*.gz'\n",
    "filelist = glob.glob(ZIPFILES)\n",
    "df = pd.DataFrame()\n",
    "for gzfile in tq.tqdm(filelist):\n",
    "    if len(df)==0:\n",
    "        df=pd.read_csv(gzfile)\n",
    "    else:\n",
    "        data = pd.read_csv(gzfile)\n",
    "        df=pd.concat([data,df])  \n",
    "print(\"File read!\")\n",
    "        \n",
    "# only selecting columns of interest\n",
    "df_select = df[[\"placekey\",\"parent_placekey\",\"location_name\",\"street_address\",\"city\",\"region\",\"brands\",\"date_range_start\",\n",
    "               \"poi_cbg\",\"visitor_home_aggregation\",\"distance_from_home\"]]\n",
    "df_select=df_select.sort_values(by=\"date_range_start\")\n",
    "\n",
    "## converting elements of columns them to its rightful type (i.e., dictionary for \"visitor_home_aggregation\" & str for \"placekey\")\n",
    "df_select[\"visitor_home_aggregation\"]=[json.loads(i) for i in tq.tqdm(list(df_select[\"visitor_home_aggregation\"]))]\n",
    "df_select = df_select.reset_index()\n",
    "df_select[\"placekey\"]=[str(i) for i in tq.tqdm(df_select[\"placekey\"])]\n",
    "df_select[\"date_range_start\"]=[str((str(i))[:7]) for i in tq.tqdm(df_select.date_range_start)]\n",
    "\n",
    "\n",
    "# inspecting all the stores and removing POIs that have been classified wrongly as convenience stores. \n",
    "print(\"identifying wrongly classified grocery stores...\")\n",
    "stores=df_select[[\"placekey\",\"location_name\"]]\n",
    "stores=stores.drop_duplicates()\n",
    "## removing punctuation and special characters from the location names of our stores so it can be easier to filter them accordingly\n",
    "stores[\"location_name\"]=[(re.sub(r'[^\\w\\s]', '', i)) for i in tq.tqdm(stores[\"location_name\"])]\n",
    "## lower spacing all of the location names so it can be easy to filter them by location name\n",
    "stores[\"location_name\"]=[i.lower() for i in tq.tqdm(stores[\"location_name\"])]\n",
    "stores[\"location_name\"]=[i.split() for i in tq.tqdm(stores[\"location_name\"])]\n",
    "stores = stores.reset_index()\n",
    "\n",
    "# removing stores that have been wrongly misclassified\n",
    "# identifying placekeys of misclassified convenience-stores\n",
    "black_list=[]\n",
    "for i in tq.tqdm(range(len(stores))):\n",
    "    current=stores.location_name[i]\n",
    "    current_placekey=str(stores.placekey[i])\n",
    "    \n",
    "    # terminologies that are clearly not associated with convenience stores. \n",
    "    list_of_unwanted=[\"bar\",\"bars\",\"deli\",\"delis\",\"sandwich\",\"sandwiches\",\"sandwichs\",\"bakery\",\"donut\",\n",
    "                     \"donuts\",\"bakerys\",\"bakeries\",\"cafe\",\"cafes\",\"coffee\",\"coffees\",\"pizza\",\"pizzas\",\"bagel\",\"bagels\"]\n",
    "    for j in (current):\n",
    "        if j in list_of_unwanted and current_placekey not in black_list:\n",
    "            black_list.append(str(current_placekey))\n",
    "        else:\n",
    "            continue\n",
    "print(\"length of list of incorrectly mislabelled convenience stores is: \", len(black_list))\n",
    "\n",
    "## removing our identified and extracted misclassified convenience-stores from our data. \n",
    "print(\"Removing incorrectly classified grocery stores...\")\n",
    "df_select=df_select[~df_select['placekey'].isin(black_list)]     \n",
    "df_select = df_select.reset_index()\n",
    "# cleaning the dataframe\n",
    "df_select=df_select.drop(['level_0', 'index'], axis=1)\n",
    "print(\"The total number of convenient store chain names selected is:\",len(list(np.unique(np.array(df_select[\"location_name\"])))))\n",
    "print(\"The number of convenient store locations selected is:\",len(list(np.unique(np.array(df_select[\"placekey\"])))))\n",
    "\n",
    "\n",
    "\n",
    "# scaling-up the visitation data from census tract to county level\n",
    "## This function converts the census tract to county's\n",
    "print(\"Scaling up visitations from census-tract level to county-level\")\n",
    "def conv_to_county(dictionary):\n",
    "    new_dict={}\n",
    "    in_the_system=[]\n",
    "    for i in dictionary.keys():\n",
    "        if str(i[:5]) in in_the_system:\n",
    "            old_value=int(new_dict[str(i[:5])])\n",
    "            to_be_added=int(dictionary[str(i)])\n",
    "            new_value=int(old_value+to_be_added)\n",
    "            new_dict[str(i[:5])]=new_value\n",
    "        else:\n",
    "            new_dict[str(i[:5])]=int(dictionary[i])\n",
    "            in_the_system.append(str(i[:5]))\n",
    "    return(new_dict)\n",
    "\n",
    "## This function compiles the visitations based on county's visitors\n",
    "def home_county(list_of_tract):\n",
    "    county_list=[]\n",
    "    for i in tq.tqdm(range(len(list_of_tract))):\n",
    "        current=list_of_tract[i]\n",
    "        new=conv_to_county(current)\n",
    "        county_list.append(new)\n",
    "    return(county_list)\n",
    "\n",
    "df_select[\"home_county\"]=home_county(df_select[\"visitor_home_aggregation\"])\n",
    "\n",
    "# # transforming the dataframe such we can now see visitors to each store from each county  \n",
    "def detailed_long_df(old_df):\n",
    "    location_list,placekey_list,date_range_start_list,county_list,count_list=[],[],[],[],[]\n",
    "    for i in tq.tqdm(range(len(df_select))):\n",
    "        location_name,placekey,date_range_start=(df_select[\"location_name\"][i]),(df_select[\"placekey\"][i]),(df_select[\"date_range_start\"][i])\n",
    "        current_home_county=(df_select[\"home_county\"][i])\n",
    "        for j in current_home_county.keys():\n",
    "            # remove visitors from Canada\n",
    "            try:\n",
    "                x=int(j) \n",
    "            except ValueError:\n",
    "                j=\"NULL\"\n",
    "            if j==\"NULL\":\n",
    "                count=0\n",
    "            else:\n",
    "                county=str(j)\n",
    "                count=int(current_home_county[j])\n",
    "            location_list.append(location_name)\n",
    "            placekey_list.append(placekey)\n",
    "            date_range_start_list.append(date_range_start)\n",
    "            county_list.append(county)\n",
    "            count_list.append(count)\n",
    "    df_detail = pd.DataFrame(list(zip(location_list,placekey_list,date_range_start_list,county_list,count_list)), columns =['location','placekey','date_range_start','county','count'])\n",
    "    return(df_detail)\n",
    "\n",
    "## executing the function above\n",
    "df_detail=detailed_long_df(df_select)\n",
    "\n",
    "## Cleaning the data to prepare for aggregation \n",
    "df_detail=df_detail[df_detail[\"county\"].str.contains(\"NULL\")==False] # removing Canada visitors\n",
    "df_detail[\"type\"]=[\"convenient store\" for i in tq.tqdm(range(len(df_detail)))]\n",
    "\n",
    "# aggregating county_level visitor stats to convenient stores\n",
    "print(\"Aggregating data...\")\n",
    "aggregated=(df_detail.groupby(['date_range_start','county','type']).agg(month_count=('count', 'sum')))\n",
    "\n",
    "# saving csv file\n",
    "aggregated = aggregated.reset_index()\n",
    "print(\"Data Aggregated, saving file...\")\n",
    "aggregated.to_csv(\"convenient_store_aggregated_by_county.csv\", index=False)\n",
    "print(\"File Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd4e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
